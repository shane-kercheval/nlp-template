{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "564aa887",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Citation\n",
    "\n",
    "Much of the code and examples are copied/modified from \n",
    "\n",
    "> Blueprints for Text Analytics Using Python by Jens Albrecht, Sidharth Ramachandran, and Christian Winkler (O'Reilly, 2021), 978-1-492-07408-3.\n",
    ">\n",
    "\n",
    "- https://github.com/blueprints-for-text-analytics-python/blueprints-text\n",
    "- https://github.com/blueprints-for-text-analytics-python/blueprints-text/blob/master/ch08/Topic_Modeling_Clustering.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a967948",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1671ff",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2615d74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this variable controls the range of n-grams used by CountVectorizer/TfidfVectorizer\n",
    "# and, therefore, the n-grams the topic modeling will use\n",
    "n_gram_range = (1, 3)\n",
    "# specify stop words specific to this dataset\n",
    "custom_stop_words = {'united', 'nations', 'nation'}\n",
    "# specify the number of topics the NMF/LDA will create\n",
    "number_of_topics = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ae0c59",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76f028ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shanekercheval/repos/nlp-template\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66085eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"source/config/notebook_settings.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f360077d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3492686a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.library.utilities import Timer, get_logger\n",
    "from source.library.text_analysis import count_tokens, tf_idf, get_context_from_keyword, count_keywords, count_keywords_by, impurity\n",
    "from source.library.sklearn_topic_modeling import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "624dedbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started: Loading Data\n",
      "Finished (0.22 seconds)\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"Loading Data\"):\n",
    "    path = 'artifacts/data/processed/un-general-debates-paragraphs.pkl'\n",
    "    paragraphs = pd.read_pickle(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e4bfed",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f055efe1",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "This section provides a basic exploration of the text and dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08db1a7f",
   "metadata": {},
   "source": [
    "## Dataset Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "596aab15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0a399_row0_col2, #T_0a399_row0_col4 {\n",
       "  width: 10em;\n",
       "}\n",
       "#T_0a399_row0_col7 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #B4B7B9 1.0%, transparent 1.0%);\n",
       "}\n",
       "#T_0a399_row0_col8 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, transparent 50.0%, #B4B7B9 50.0%, #B4B7B9 51.2%, transparent 51.2%);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0a399\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0a399_level0_col0\" class=\"col_heading level0 col0\" ># of Non-Nulls</th>\n",
       "      <th id=\"T_0a399_level0_col1\" class=\"col_heading level0 col1\" ># of Nulls</th>\n",
       "      <th id=\"T_0a399_level0_col2\" class=\"col_heading level0 col2\" >% Nulls</th>\n",
       "      <th id=\"T_0a399_level0_col3\" class=\"col_heading level0 col3\" ># of Zeros</th>\n",
       "      <th id=\"T_0a399_level0_col4\" class=\"col_heading level0 col4\" >% Zeros</th>\n",
       "      <th id=\"T_0a399_level0_col5\" class=\"col_heading level0 col5\" >Mean</th>\n",
       "      <th id=\"T_0a399_level0_col6\" class=\"col_heading level0 col6\" >St Dev.</th>\n",
       "      <th id=\"T_0a399_level0_col7\" class=\"col_heading level0 col7\" >Coef of Var</th>\n",
       "      <th id=\"T_0a399_level0_col8\" class=\"col_heading level0 col8\" >Skewness</th>\n",
       "      <th id=\"T_0a399_level0_col9\" class=\"col_heading level0 col9\" >Kurtosis</th>\n",
       "      <th id=\"T_0a399_level0_col10\" class=\"col_heading level0 col10\" >Min</th>\n",
       "      <th id=\"T_0a399_level0_col11\" class=\"col_heading level0 col11\" >10%</th>\n",
       "      <th id=\"T_0a399_level0_col12\" class=\"col_heading level0 col12\" >25%</th>\n",
       "      <th id=\"T_0a399_level0_col13\" class=\"col_heading level0 col13\" >50%</th>\n",
       "      <th id=\"T_0a399_level0_col14\" class=\"col_heading level0 col14\" >75%</th>\n",
       "      <th id=\"T_0a399_level0_col15\" class=\"col_heading level0 col15\" >90%</th>\n",
       "      <th id=\"T_0a399_level0_col16\" class=\"col_heading level0 col16\" >Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0a399_level0_row0\" class=\"row_heading level0 row0\" >year</th>\n",
       "      <td id=\"T_0a399_row0_col0\" class=\"data row0 col0\" >279,045</td>\n",
       "      <td id=\"T_0a399_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "      <td id=\"T_0a399_row0_col2\" class=\"data row0 col2\" >0.0%</td>\n",
       "      <td id=\"T_0a399_row0_col3\" class=\"data row0 col3\" >0</td>\n",
       "      <td id=\"T_0a399_row0_col4\" class=\"data row0 col4\" >0.0%</td>\n",
       "      <td id=\"T_0a399_row0_col5\" class=\"data row0 col5\" >1,992.4</td>\n",
       "      <td id=\"T_0a399_row0_col6\" class=\"data row0 col6\" >12.6</td>\n",
       "      <td id=\"T_0a399_row0_col7\" class=\"data row0 col7\" >0.0</td>\n",
       "      <td id=\"T_0a399_row0_col8\" class=\"data row0 col8\" >0.1</td>\n",
       "      <td id=\"T_0a399_row0_col9\" class=\"data row0 col9\" >-1.1</td>\n",
       "      <td id=\"T_0a399_row0_col10\" class=\"data row0 col10\" >1,970</td>\n",
       "      <td id=\"T_0a399_row0_col11\" class=\"data row0 col11\" >1,975.0</td>\n",
       "      <td id=\"T_0a399_row0_col12\" class=\"data row0 col12\" >1,982.0</td>\n",
       "      <td id=\"T_0a399_row0_col13\" class=\"data row0 col13\" >1,993.0</td>\n",
       "      <td id=\"T_0a399_row0_col14\" class=\"data row0 col14\" >2,003.0</td>\n",
       "      <td id=\"T_0a399_row0_col15\" class=\"data row0 col15\" >2,010.0</td>\n",
       "      <td id=\"T_0a399_row0_col16\" class=\"data row0 col16\" >2,015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1686910a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hlp.pandas.numeric_summary(paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da917720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4972c_row0_col2, #T_4972c_row1_col2 {\n",
       "  width: 10em;\n",
       "}\n",
       "#T_4972c_row0_col5 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #B4B7B9 0.1%, transparent 0.1%);\n",
       "}\n",
       "#T_4972c_row1_col5 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #B4B7B9 99.9%, transparent 99.9%);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4972c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4972c_level0_col0\" class=\"col_heading level0 col0\" ># of Non-Nulls</th>\n",
       "      <th id=\"T_4972c_level0_col1\" class=\"col_heading level0 col1\" ># of Nulls</th>\n",
       "      <th id=\"T_4972c_level0_col2\" class=\"col_heading level0 col2\" >% Nulls</th>\n",
       "      <th id=\"T_4972c_level0_col3\" class=\"col_heading level0 col3\" >Most Freq. Value</th>\n",
       "      <th id=\"T_4972c_level0_col4\" class=\"col_heading level0 col4\" ># of Unique</th>\n",
       "      <th id=\"T_4972c_level0_col5\" class=\"col_heading level0 col5\" >% Unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4972c_level0_row0\" class=\"row_heading level0 row0\" >country</th>\n",
       "      <td id=\"T_4972c_row0_col0\" class=\"data row0 col0\" >279,045</td>\n",
       "      <td id=\"T_4972c_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "      <td id=\"T_4972c_row0_col2\" class=\"data row0 col2\" >0.0%</td>\n",
       "      <td id=\"T_4972c_row0_col3\" class=\"data row0 col3\" >Russian Federation</td>\n",
       "      <td id=\"T_4972c_row0_col4\" class=\"data row0 col4\" >199</td>\n",
       "      <td id=\"T_4972c_row0_col5\" class=\"data row0 col5\" >0.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4972c_level0_row1\" class=\"row_heading level0 row1\" >text</th>\n",
       "      <td id=\"T_4972c_row1_col0\" class=\"data row1 col0\" >279,045</td>\n",
       "      <td id=\"T_4972c_row1_col1\" class=\"data row1 col1\" >0</td>\n",
       "      <td id=\"T_4972c_row1_col2\" class=\"data row1 col2\" >0.0%</td>\n",
       "      <td id=\"T_4972c_row1_col3\" class=\"data row1 col3\" >The President returned to the [...]</td>\n",
       "      <td id=\"T_4972c_row1_col4\" class=\"data row1 col4\" >278,820</td>\n",
       "      <td id=\"T_4972c_row1_col5\" class=\"data row1 col5\" >99.9%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x16868b3a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hlp.pandas.non_numeric_summary(paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ed8f32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not (paragraphs['text'].str.strip() == '').any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1d9b69",
   "metadata": {},
   "source": [
    "# Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9228aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7813d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords |= custom_stop_words\n",
    "stopwords |= {'ll', 've'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228131ad",
   "metadata": {},
   "source": [
    "## Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7986ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = paragraphs.sample(2000)\n",
    "#paragraphs.to_pickle('source/tests/test_files/datasets/un_debates_paragraphs_sample.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41cb0a9",
   "metadata": {},
   "source": [
    "## TF / TF-IDF\n",
    "\n",
    "NOTE: `TF` seems to be used with `LDA` rather than `TF-IDF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d264860a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started: Calculating TF & TF-IDF (1-3 ngrams)\n",
      "(2000, 3489)\n",
      "Finished (0.36 seconds)\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"Calculating TF & TF-IDF (1-3 ngrams)\"):\n",
    "    count_vectorizer = CountVectorizer(stop_words=stopwords, ngram_range=(1, 3), min_df=5, max_df=0.7)\n",
    "    count_vectors = count_vectorizer.fit_transform(paragraphs[\"text\"])\n",
    "    print(count_vectors.shape)\n",
    "\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words=stopwords, ngram_range=(1, 3), min_df=5, max_df=0.7)\n",
    "    tfidf_vectors = tfidf_vectorizer.fit_transform(paragraphs[\"text\"])\n",
    "    tfidf_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d2f9a9",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "213fe909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_top_words(model, feature_names, n_top_words, title):\n",
    "    \"\"\"\n",
    "    https://scikit-learn.org/stable/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html#sphx-glr-auto-examples-applications-plot-topics-extraction-with-nmf-lda-py\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(30, 15), sharex=True)\n",
    "    axes = axes.flatten()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_features_ind = topic.argsort()[: -n_top_words - 1 : -1]\n",
    "        top_features = [feature_names[i] for i in top_features_ind]\n",
    "        weights = topic[top_features_ind]\n",
    "\n",
    "        ax = axes[topic_idx]\n",
    "        ax.barh(top_features, weights, height=0.7)\n",
    "        ax.set_title(f\"Topic {topic_idx +1}\", fontdict={\"fontsize\": 30})\n",
    "        ax.invert_yaxis()\n",
    "        ax.tick_params(axis=\"both\", which=\"major\", labelsize=20)\n",
    "        for i in \"top right left\".split():\n",
    "            ax.spines[i].set_visible(False)\n",
    "        fig.suptitle(title, fontsize=40)\n",
    "\n",
    "    plt.subplots_adjust(top=0.90, bottom=0.05, wspace=0.90, hspace=0.3)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf8c3e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b63575ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, features, no_top_words=5):\n",
    "    for topic, words in enumerate(model.components_):\n",
    "        total = words.sum()\n",
    "        largest = words.argsort()[::-1] # invert sort order\n",
    "        print(\"\\nTopic %02d\" % topic)\n",
    "        for i in range(0, no_top_words):\n",
    "            print(\"  %s (%2.2f)\" % (features[largest[i]], abs(words[largest[i]]*100.0/total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f7911b",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0683b33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf_model = NMF(init='nndsvda', n_components=number_of_topics, random_state=42, max_iter=1000)\n",
    "_ = nmf_model.fit_transform(tfidf_vectors)\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd07bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_df = extract_topic_dataframe(\n",
    "    model=nmf_model,\n",
    "    features=feature_names,\n",
    "    top_n_tokens=10,\n",
    "    num_tokens_in_label=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197bf794",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_topics(topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1ba70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_sizes = calculate_topic_sizes(nmf_model, count_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1976f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dict = extract_topic_dictionary(nmf_model, feature_names)\n",
    "topic_labels = list(create_topic_labels(topic_dict).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891f6efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Topics': topic_labels,\n",
    "    'Topic Size as a Percent of the Dataset': topic_sizes,\n",
    "})\n",
    "\n",
    "fig = px.bar(\n",
    "    df,\n",
    "    x='Topic Size as a Percent of the Dataset',\n",
    "    y='Topics',\n",
    "    title='Size of Topics<br><sup>More than 1 topic can be assigned to a single document; therefore, relative (percentage) sizes are provided.</sup>'\n",
    ")\n",
    "fig.update_layout(xaxis_tickformat = 'p')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c00b7d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86b6238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a80466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abebfe76",
   "metadata": {},
   "source": [
    "Get Topic Weightings for First Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdc9a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topics for first document \n",
    "w_first_doc = w_matrix_unigrams[0, ]\n",
    "w_first_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c2b648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be the same values as before\n",
    "predictions_first_doc = nmf_unigrams.transform(tfidf_vectors_unigrams[0,])\n",
    "predictions_first_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f1010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "[abs(round(x, 4)) for x in (w_first_doc - predictions_first_doc).tolist()[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf84476",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1d8517",
   "metadata": {},
   "source": [
    "Get Top 10 Words for First Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548b2c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_topic = h_matrix_unigrams[0,]\n",
    "first_topic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aae068",
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_word_values = first_topic.argsort()[::-1]\n",
    "largest_word_values[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a05886",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_names[largest_word_values[0:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf5571e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf79a07e",
   "metadata": {},
   "source": [
    "Size of Topics (Percent of all Documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00160108",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_matrix_unigrams.sum(axis=0)/w_matrix_unigrams.sum()*100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67db6f28",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c16a54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topics_to_dictionary(model, features, num_top_words=10):\n",
    "    topics = dict()\n",
    "    for topic, words in enumerate(model.components_):\n",
    "        total = words.sum()\n",
    "        largest = words.argsort()[::-1] # invert sort order\n",
    "        topics[topic + 1] = [(features[largest[i]], abs(words[largest[i]]*100.0/total)) for i in range(0, num_top_words)]\n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fa75b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dictionary = topics_to_dictionary(nmf_unigrams, tfidf_vectorizer_unigrams.get_feature_names_out())\n",
    "#topic_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65f2dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_lookup = {topic:' | '.join([y[0] for y in x[0:3]]) for topic, x in topic_dictionary.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184ae8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_dictionary_to_names(topic_dictionary: dict, num_words_in_name: int=3):\n",
    "    return {topic:' | '.join([y[0] for y in x[0:num_words_in_name]]) for topic, x in topic_dictionary.items()}\n",
    "\n",
    "name_lookup = topic_dictionary_to_names(topic_dictionary, num_words_in_name=2)\n",
    "name_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22277194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topics_to_dataframe(model, features: list, num_top_words: int = 10, num_words_in_name: int = 2) -> pd.DataFrame:\n",
    "    topic_dictionary = topics_to_dictionary(model, features, num_top_words)\n",
    "    name_lookup = topic_dictionary_to_names(topic_dictionary, num_words_in_name=num_words_in_name)\n",
    "    \n",
    "    topic_words = pd.DataFrame(topic_dictionary)\n",
    "    topics = topic_words.columns\n",
    "    topic_words = topic_words.reset_index().rename(columns={'index': 'word'})\n",
    "    topic_words = pd.melt(topic_words, id_vars='word', value_vars=list(topics), var_name='topic')\n",
    "    topic_words = topic_words.assign(**pd.DataFrame(topic_words['value'].tolist(), columns=['words', 'value']))\n",
    "    topic_words['label'] = topic_words['topic'].apply(lambda x: name_lookup[x])\n",
    "    return topic_words\n",
    "\n",
    "topic_df = topics_to_dataframe(\n",
    "    model=nmf_unigrams,\n",
    "    features=tfidf_vectorizer_unigrams.get_feature_names_out(),\n",
    "    num_top_words=10,\n",
    "    num_words_in_name=2,\n",
    ")\n",
    "topic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de134f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_words = pd.DataFrame(topic_dictionary)\n",
    "# topics = topic_words.columns\n",
    "# topic_words = topic_words.reset_index().rename(columns={'index': 'word'})\n",
    "# topic_words = pd.melt(topic_words, id_vars='word', value_vars=list(topics), var_name='topic')\n",
    "# topic_words = topic_words.assign(**pd.DataFrame(topic_words['value'].tolist(), columns=['words', 'value']))\n",
    "# topic_words['label'] = topic_words['topic'].apply(lambda x: name_lookup[x])\n",
    "# topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2d9650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly_express as px\n",
    "\n",
    "fig = px.bar(\n",
    "    topic_df,\n",
    "    x='value',\n",
    "    y='words',\n",
    "    facet_col='label',\n",
    "    facet_col_wrap=3,\n",
    "    facet_col_spacing=0.2,\n",
    "    labels={\n",
    "        'words': '',\n",
    "        'label': '',\n",
    "    },\n",
    "    width=900,\n",
    "    height=1000,\n",
    "    title=\"Topics in NMF model (Unigrams)\"\n",
    ")\n",
    "fig.update_yaxes(matches=None, showticklabels=True, autorange=\"reversed\")\n",
    "#fig.update_xaxes(matches=None)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a063ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_words(\n",
    "    model=nmf_unigrams,\n",
    "    feature_names=tfidf_vectorizer_unigrams.get_feature_names_out(),\n",
    "    n_top_words=5,\n",
    "    title=\"Topics in NMF model (Uni-grams)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526ccf33",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b89e299",
   "metadata": {},
   "source": [
    "### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43aea2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_bigrams = NMF(n_components=10, random_state=42)\n",
    "# see Blueprints pg. 214 for explaination of W X H\n",
    "w_matrix_bigrams = nmf_bigrams.fit_transform(tfidf_vectors_bigrams)\n",
    "h_matrix_bigrams = nmf_bigrams.components_\n",
    "word_names = tfidf_vectorizer_bigrams.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2229e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display_topics(nmf_para_model_bigrams, tfidf_para_vectorizer_bigrams.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbca133",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "topic_df = topics_to_dataframe(\n",
    "    model=nmf_bigrams,\n",
    "    features=tfidf_vectorizer_bigrams.get_feature_names_out(),\n",
    "    num_top_words=10,\n",
    "    num_words_in_name=2,\n",
    ")\n",
    "topic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c8b4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly_express as px\n",
    "\n",
    "fig = px.bar(\n",
    "    topic_df,\n",
    "    x='value',\n",
    "    y='words',\n",
    "    facet_col='label',\n",
    "    facet_col_wrap=2,\n",
    "    facet_col_spacing=0.2,\n",
    "    labels={\n",
    "        'words': '',\n",
    "        'label': '',\n",
    "    },\n",
    "    width=900,\n",
    "    height=1000,\n",
    "    title=\"Topics in NMF model (Bigrams)\"\n",
    ")\n",
    "fig.update_yaxes(matches=None, showticklabels=True, autorange=\"reversed\")\n",
    "#fig.update_xaxes(matches=None)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5789ddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_words(\n",
    "    model=nmf_bigrams,\n",
    "    feature_names=tfidf_vectorizer_bigrams.get_feature_names_out(),\n",
    "    n_top_words=5,\n",
    "    title=\"Topics in NMF model (Bi-grams)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ce38d4",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html#sphx-glr-auto-examples-applications-plot-topics-extraction-with-nmf-lda-py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a99ab67",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7987ee65",
   "metadata": {},
   "source": [
    "Neither the book nor the example above uses TF-IDF with LDA, but do not specify why. Both use TF-IDF with NMF and then change to CountVectorizer with LDA\n",
    "\n",
    "\n",
    "https://stackoverflow.com/questions/44781047/necessary-to-apply-tf-idf-to-new-documents-in-gensim-lda-model/44789327#44789327\n",
    "\n",
    "> LDA only needs a bag-of-word vector.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ddb9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_para_vectorizer_bigrams = CountVectorizer(stop_words=stopwords, min_df=5, max_df=0.7, ngram_range=(2,3))\n",
    "count_para_vectors_bigrams = count_para_vectorizer_bigrams.fit_transform(paragraphs[\"text\"])\n",
    "count_para_vectors_bigrams.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2685de1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_para_vectorizer_bigrams = CountVectorizer(stop_words=stopwords, min_df=5, max_df=0.7, ngram_range=(2,3))\n",
    "count_para_vectors_bigrams = count_para_vectorizer_bigrams.fit_transform(paragraphs[\"text\"])\n",
    "count_para_vectors_bigrams.shape\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_para_vectorizer = CountVectorizer(stop_words=stopwords, min_df=5, max_df=0.7)\n",
    "count_para_vectors = count_para_vectorizer.fit_transform(paragraphs[\"text\"])\n",
    "count_para_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0f73a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda_para_model = LatentDirichletAllocation(n_components = 10, random_state=42)\n",
    "W_lda_para_matrix = lda_para_model.fit_transform(count_para_vectors)\n",
    "H_lda_para_matrix = lda_para_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1b6e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_words(\n",
    "    model=lda_para_model,\n",
    "    feature_names=count_para_vectorizer.get_feature_names_out(),\n",
    "    n_top_words=5,\n",
    "    title=\"Topics in LDA model (Uni-grams)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a4375e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cdf66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_lda_para_matrix.sum(axis=0)/W_lda_para_matrix.sum()*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a34e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a112e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda_para_model_bigrams = LatentDirichletAllocation(n_components = 10, random_state=42)\n",
    "W_lda_para_matrix_bigrams = lda_para_model_bigrams.fit_transform(count_para_vectors_bigrams)\n",
    "H_lda_para_matrix_bigrams = lda_para_model_bigrams.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bce47b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_top_words(model, feature_names, n_top_words, title):\n",
    "    \"\"\"\n",
    "    https://scikit-learn.org/stable/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html#sphx-glr-auto-examples-applications-plot-topics-extraction-with-nmf-lda-py\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(30, 15), sharex=True)\n",
    "    axes = axes.flatten()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_features_ind = topic.argsort()[: -n_top_words - 1 : -1]\n",
    "        top_features = [feature_names[i] for i in top_features_ind]\n",
    "        weights = topic[top_features_ind]\n",
    "\n",
    "        ax = axes[topic_idx]\n",
    "        ax.barh(top_features, weights, height=0.7)\n",
    "        ax.set_title(f\"Topic {topic_idx +1}\", fontdict={\"fontsize\": 30})\n",
    "        ax.invert_yaxis()\n",
    "        ax.tick_params(axis=\"both\", which=\"major\", labelsize=20)\n",
    "        for i in \"top right left\".split():\n",
    "            ax.spines[i].set_visible(False)\n",
    "        fig.suptitle(title, fontsize=40)\n",
    "\n",
    "    plt.subplots_adjust(top=0.90, bottom=0.05, wspace=0.90, hspace=0.3)\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b9e256",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_words(\n",
    "    model=lda_para_model_bigrams,\n",
    "    feature_names=count_para_vectorizer_bigrams.get_feature_names_out(),\n",
    "    n_top_words=5,\n",
    "    title=\"Topics in LDA model (Bi-grams)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a56cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635f0fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9779e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6aa948",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1115d157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091ed8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.sklearn\n",
    "\n",
    "lda_display = pyLDAvis.sklearn.prepare(lda_para_model, count_para_vectors, count_para_vectorizer, sort_topics=False)\n",
    "#pyLDAvis.display(lda_display)\n",
    "pyLDAvis.save_html(lda_display, 'docs/models/lda.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fe50b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8614b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.sklearn\n",
    "\n",
    "lda_display = pyLDAvis.sklearn.prepare(lda_para_model_bigrams, count_para_vectors_bigrams, count_para_vectorizer_bigrams, sort_topics=False)\n",
    "#pyLDAvis.display(lda_display)\n",
    "pyLDAvis.save_html(lda_display, 'docs/models/lda_bigrams.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bee055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b5ea39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e8c39b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "235px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
